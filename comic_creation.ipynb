{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Mistral Nemo for dialogue and embed dialogue in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "# def embedding(image_paths, prompt):\n",
    "def embed_text_as_image_novel(image_path, text):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Set up the font and size\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 20)  # You can customize the font and size\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Wrap the text to fit the image width\n",
    "    max_width = image.width - 20  # Leave some padding\n",
    "    wrapped_text = textwrap.fill(text, width=40)  # Adjust width as needed\n",
    "\n",
    "    # Calculate text size using textbbox\n",
    "    text_bbox = draw.textbbox((0, 0), wrapped_text, font=font)\n",
    "    text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
    "\n",
    "    # Calculate text position at the bottom of the image\n",
    "    padding = 10\n",
    "    text_position = (10, image.height - text_height - padding)  # Adjust padding if needed\n",
    "\n",
    "    # Draw a rectangle behind the text for better visibility (optional)\n",
    "    rectangle_bbox = [text_position[0] - 5, text_position[1] - 5, \n",
    "                    text_position[0] + text_width + 5, text_position[1] + text_height + 5]\n",
    "    draw.rectangle(rectangle_bbox, fill=\"black\")\n",
    "\n",
    "    # Draw the text on the image\n",
    "    draw.text(text_position, wrapped_text, font=font, fill=\"white\")\n",
    "\n",
    "    # Save the image with the embedded text\n",
    "    output_path = \"output_\" + image_path.split('/')[-1]  # Prepend 'output_' to the filename\n",
    "    image.save(output_path)\n",
    "    return output_path\n",
    "\n",
    "def display_image(image_path):\n",
    "    # Open the image using PIL\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "def generate_text_with_mistral(prompt, image_path):\n",
    "    try:\n",
    "        # Call the CLI command, adjust as per the actual command structure\n",
    "        command = [\"ollama\", \"run\", \"mistral-nemo\", image_path]\n",
    "        result = subprocess.run(\n",
    "            command, input=prompt,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        # Check for errors\n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"Error generating text: {result.stderr}\")\n",
    "        \n",
    "        return result.stdout.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_images_sequentially(image_paths, prompt):\n",
    "    comic_data = []\n",
    "    \n",
    "# for i, image_path in enumerate(image_paths):\n",
    "    # Generate the dialogue for each image sequentially using the same prompt\n",
    "    generated_text = generate_text_with_mistral(prompt, image_paths)\n",
    "    \n",
    "    # Store the image and its corresponding dialogue in the dictionary\n",
    "    \n",
    "    \n",
    "    # Embed the dialogue into the image\n",
    "    output_image_path = embed_text_as_image_novel(image_paths, generated_text)\n",
    "    comic_data.append(output_image_path)\n",
    "    print(f\"Generated Text for {image_paths}: {generated_text}\")\n",
    "    print(f\"Output Image Path: {output_image_path}\")\n",
    "\n",
    "    # Display the image\n",
    "    display_image(output_image_path)\n",
    "\n",
    "        # return comic_data\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "desc = \"Scientist Tom makes a significant discovery in biology lab.\"\n",
    "\n",
    "prompt = f\"I want you to follow the scientific description {desc} for the image i shall provide. I want you to Generate JUST ONE small dialogue WITH THE PERSON SPEAKING STORY WISE for image and no other text.\"\n",
    "\n",
    "process_images_sequentially(\"output.png\", prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
